
import { ChatOrchestrator } from '@/lib/infrastructure/ai/chat-orchestrator';
import { IntegratedChatRepository } from '@/lib/infrastructure/database/repositories/integrated-chat-repository';
import { openai } from '@ai-sdk/openai';
import { generateText, stepCountIs } from 'ai';

const TELEGRAM_TOKEN = process.env.TELEGRAM_BOT_TOKEN;

async function sendTelegramMessage(chatId: string | number, text: string) {
    if (!TELEGRAM_TOKEN) {
        console.error('TELEGRAM_BOT_TOKEN not set');
        return;
    }
    const url = `https://api.telegram.org/bot${TELEGRAM_TOKEN}/sendMessage`;
    try {
        await fetch(url, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                chat_id: chatId,
                text: text,
                parse_mode: 'Markdown' // Optional: support markdown
            })
        });
    } catch (e) {
        console.error('Failed to send Telegram message', e);
    }
}

export async function POST(req: Request) {
    try {
        const update = await req.json();

        // Basic validation of update structure
        if (!update.message || !update.message.text) {
            return Response.json({ ok: true }); // Acknowledge to stop retries
        }

        const chatId = String(update.message.chat.id);
        const userText = update.message.text;

        console.log(`ðŸ“© Telegram Message from ${chatId}: ${userText}`);

        // 1. Get History
        const history = await IntegratedChatRepository.getHistory('telegram', chatId);

        // 2. Prepare Messages
        const incomingMessage: any = { role: 'user', content: userText };
        const conversation = [...history, incomingMessage];

        // 3. Process with Orchestrator
        const {
            isValid,
            validationError,
            modelMessages,
            agentConfig
        } = await ChatOrchestrator.processMessage(conversation);

        if (!isValid) {
            await sendTelegramMessage(chatId, validationError || "I couldn't process your message.");
            return Response.json({ ok: true });
        }

        // 4. Generate Response (Non-streaming)
        const result = await generateText({
            model: openai('gpt-4o'),
            messages: modelMessages,
            system: agentConfig.systemPrompt,
            tools: agentConfig.tools,
            toolChoice: 'auto',
            stopWhen: stepCountIs(5),
        });

        const aiText = result.text;
        console.log(`ðŸ¤– AI Response: ${aiText}`);

        // 5. Update History
        // We append the incoming message AND the AI response(s)
        // result.response.messages contains the full trace including tool calls if any were made
        // But for simple history storage we might just want the final text? 
        // NO, the Orchestrator needs previous tool calls to maintain context if we want to continue.
        // So we should append ALL new messages generated in this turn.

        const newMessagesFromAI = result.response.messages;
        // Note: result.response.messages includes the input messages too? 
        // Check AI SDK docs: result.response.messages are the messages *generated*? 
        // Actually generateText result.response.messages usually contains the FULL sequence if roundtrips happened?
        // Wait, `result.messages` (if available) or we construct it.
        // `generateText` returns `text`, `toolCalls`, `toolResults` etc.
        // If `maxSteps` > 1, the intermediate steps are important.
        // `result.response.messages` gives the messages generated by the model calls.

        // Let's rely on `result.steps` to reconstruct or just save the final turn if we want to simplify.
        // But true agent checks need tool outputs history.
        // `result.messages` contains the request messages + generated messages.

        // Safest approach: Append `incomingMessage` and then the *new* content from AI.
        // However, `result.steps` might be complex to serialize perfectly if we use standard simple ModelMessage logic.
        // BUT, `integrated_chats` stores `jsonb`, so we can store complex objects.

        // Let's use `result.response.messages` which should be the *new* messages added during generation?
        // Documentation says: `response.messages`: The messages generated by the model.

        const messagesToSave = [incomingMessage, ...result.response.messages];
        await IntegratedChatRepository.appendToHistory('telegram', chatId, messagesToSave);

        // 6. Send Response
        // If there are multiple text parts (from steps), we might want to consolidate or send multiple?
        // Usually `result.text` is the final answer.
        console.log(`ðŸ“¤ Sending Telegram response to ${chatId}`);
        await sendTelegramMessage(chatId, aiText);

        return Response.json({ ok: true });

    } catch (error) {
        console.error('Telegram Webhook Error:', error);
        return Response.json({ error: 'Internal Server Error' }, { status: 500 });
    }
}
